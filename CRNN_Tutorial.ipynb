{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Plate Detection using Deep Learning\n",
    "## This page proposes a model for license plate recognition using one of the deep learning models (CRNN).\n",
    "\n",
    "The code or tutorial here was created with reference to the following site: [https://github.com/qjadud1994/CRNN-Keras]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downLoad Github\n",
    "!git clone https://github.com/LEE-SEON-WOO/CRNN-Keras\n",
    "!pwd\n",
    "!ls -al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Diriectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('CRNN-Keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Plate Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import random\n",
    "import cv2, argparse\n",
    "import numpy as np\n",
    "from Generator_original import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ImageGenerator('./DB/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 finish\n",
      "Type 2 finish\n",
      "Type 3 finish\n",
      "Type 4 finish\n",
      "Type 5 finish\n"
     ]
    }
   ],
   "source": [
    "img_dir =\"./DB/train/\"\n",
    "img_num = 100\n",
    "A = ImageGenerator(img_dir)\n",
    "\n",
    "num_img = img_num\n",
    "\n",
    "\n",
    "A.Type_1(num_img, save=True)\n",
    "print(\"Type 1 finish\")\n",
    "A.Type_2(num_img, save=True)\n",
    "print(\"Type 2 finish\")\n",
    "A.Type_3(num_img, save=True)\n",
    "print(\"Type 3 finish\")\n",
    "A.Type_4(num_img, save=True)\n",
    "print(\"Type 4 finish\")\n",
    "A.Type_5(num_img, save=True)\n",
    "print(\"Type 5 finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import Lib\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from Model import get_Model\n",
    "K.set_learning_phase(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_VECTOR = \"adefghjknqrstwABCDEFGHIJKLMNOPZ0123456789\"\n",
    "\n",
    "letters = [letter for letter in CHAR_VECTOR]\n",
    "\n",
    "num_classes = len(letters) + 1\n",
    "\n",
    "img_w, img_h = 128, 64\n",
    "\n",
    "# Network parameters\n",
    "batch_size = 128\n",
    "val_batch_size = 16\n",
    "\n",
    "downsample_factor = 4\n",
    "max_text_len = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "\n",
    "import cv2\n",
    "import os, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input data generator\n",
    "def labels_to_text(labels):     # ndex if letters -> text (string)\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):      # text to letters return from index value of array \n",
    "    return list(map(lambda x: letters.index(x), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextImageGenerator:\n",
    "    def __init__(self, img_dirpath, img_w, img_h,\n",
    "                 batch_size, downsample_factor, max_text_len=9):\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.img_dirpath = img_dirpath                  # image dir path\n",
    "        self.img_dir = os.listdir(self.img_dirpath)     # images list\n",
    "        self.n = len(self.img_dir)                      # number of images\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "\n",
    "    ## samples의 이미지 목록들을 opencv로 읽어 저장하기, texts에는 label 저장\n",
    "    def build_data(self):\n",
    "        print(self.n, \" Image Loading start...\")\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = cv2.imread(self.img_dirpath + img_file, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img.astype(np.float32)\n",
    "            img = (img / 255.0) * 2.0 - 1.0\n",
    "\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(img_file[0:-4])\n",
    "        print(len(self.texts) == self.n)\n",
    "        print(self.n, \" Image Loading finish...\")\n",
    "\n",
    "    def next_sample(self):      ## index max -> 0 으로 만들기\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "\n",
    "    def next_batch(self):       ## batch size만큼 가져오기\n",
    "        while True:\n",
    "            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])     # (bs, 128, 64, 1)\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])             # (bs, 9)\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)  # (bs, 1)\n",
    "            label_length = np.zeros((self.batch_size, 1))           # (bs, 1)\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                label_length[i] = len(text)\n",
    "\n",
    "            # dict 형태로 복사\n",
    "            inputs = {\n",
    "                'the_input': X_data,  # (bs, 128, 64, 1)\n",
    "                'the_labels': Y_data,  # (bs, 8)\n",
    "                'input_length': input_length,  # (bs, 1) -> 모든 원소 value = 30\n",
    "                'label_length': label_length  # (bs, 1) -> 모든 원소 value = 8\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1) -> 모든 원소 0\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from parameter import *\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG + Bidirectional LSTM (CTC loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss and train functions, network architecture\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def get_Model(training):\n",
    "    input_shape = (img_w, img_h, 1)     # (128, 64, 1)\n",
    "\n",
    "    # Make Networkw\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 128, 64, 1)\n",
    "\n",
    "    # Convolution layer (VGG)\n",
    "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 64, 64)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n",
    "\n",
    "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
    "\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)\n",
    "\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
    "\n",
    "    inner = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "\n",
    "    # CNN to RNN\n",
    "    inner = Reshape(target_shape=((32, 2048)), name='reshape')(inner)  # (None, 32, 2048)\n",
    "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
    "\n",
    "    # RNN layer\n",
    "    '''\n",
    "    lstm_1 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n",
    "    lstm_1b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
    "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "\n",
    "    lstm_2 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "    '''\n",
    "\n",
    "    lstm1_merged = Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(inner)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    lstm2_merged = Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(lstm1_merged)\n",
    "    \n",
    "    \n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    \n",
    "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4253: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "...New weight data...\n",
      "500  Image Loading start...\n",
      "True\n",
      "500  Image Loading finish...\n",
      "0  Image Loading start...\n",
      "True\n",
      "0  Image Loading finish...\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 64, 64)  256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 64, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 32, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 16, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 8, 512)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 4, 512)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 2048)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32, 256)      657408      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 256)      1024        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 32, 512)      1050624     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 42)       21546       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 42)       0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,419,498\n",
      "Trainable params: 7,414,506\n",
      "Non-trainable params: 4,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`validation_steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `validation_steps` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dfb98029fa0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtiger_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                     validation_steps=int(tiger_val.n / val_batch_size))\n\u001b[0m",
      "\u001b[1;32mC:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Miniconda3\\envs\\crnn\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     66\u001b[0m     if (val_gen and not isinstance(validation_data, Sequence) and\n\u001b[0;32m     67\u001b[0m             not validation_steps):\n\u001b[1;32m---> 68\u001b[1;33m         raise ValueError('`validation_steps=None` is only valid for a'\n\u001b[0m\u001b[0;32m     69\u001b[0m                          \u001b[1;34m' generator based on the `keras.utils.Sequence`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                          \u001b[1;34m' class. Please specify `validation_steps` or use'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `validation_steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `validation_steps` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "# # Model description and training\n",
    "model = get_Model(training=True)\n",
    "try:\n",
    "    model.load_weights('LSTM+BN4--26--0.011.hdf5')\n",
    "    print(\"...Previous weight data...\")\n",
    "except:\n",
    "    print(\"...New weight data...\")\n",
    "    pass\n",
    "\n",
    "train_file_path = './DB/train/'\n",
    "tiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor)\n",
    "tiger_train.build_data()\n",
    "\n",
    "valid_file_path = './DB/test/'\n",
    "tiger_val = TextImageGenerator(valid_file_path, img_w, img_h, val_batch_size, downsample_factor)\n",
    "tiger_val.build_data()\n",
    "\n",
    "ada = Adadelta()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=4, mode='min', verbose=0)\n",
    "checkpoint = ModelCheckpoint(filepath='LSTM+BN5--{epoch:02d}--{val_loss:.3f}.hdf5', monitor='loss', verbose=1, mode='min', period=10)\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n",
    "model.summary()\n",
    "# captures output of softmax so we can decode the output during visualization\n",
    "model.fit_generator(generator=tiger_train.next_batch(),\n",
    "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
    "                    epochs=30,\n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=tiger_val.next_batch(),\n",
    "                    validation_steps=int(tiger_val.n / val_batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
